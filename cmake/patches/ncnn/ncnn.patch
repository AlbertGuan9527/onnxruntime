diff --git a/CMakeLists.txt b/CMakeLists.txt
index a67ab6af..10fae775 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -595,10 +595,20 @@ endif()
 if(NCNN_VULKAN)
     if(NCNN_SYSTEM_GLSLANG)
         find_package(Threads)
-        find_package(glslang QUIET)
+        # find_package fails for glslang but onnxruntime_fetchcontent_makeavailable has created all the necessary
+        # targets and we manually set glslang_FOUND to indicate this.
+        # Side note: it could be that onnxruntime_fetchcontent_makeavailable does not implement the cmake 3.24
+        # FetchContent redirection mode and if it did the find_package here would work.
+        if (NOT glslang_FOUND)
+            find_package(glslang QUIET)
+        endif()
+        message(STATUS "glslang_FOUND: ${glslang_FOUND}")
         if(glslang_FOUND)
-            add_library(glslang ALIAS glslang::glslang)
-            add_library(SPIRV ALIAS glslang::SPIRV)
+            # Add glslang libraries if they are not already targets
+            if(NOT TARGET glslang)
+                add_library(glslang ALIAS glslang::glslang)
+                add_library(SPIRV ALIAS glslang::SPIRV)
+            endif()
         else()
             set(GLSLANG_TARGET_DIR "GLSLANG-NOTFOUND" CACHE PATH "Absolute path to glslangTargets.cmake directory")
             if(NOT GLSLANG_TARGET_DIR AND NOT DEFINED ENV{GLSLANG_TARGET_DIR})
diff --git a/src/command.cpp b/src/command.cpp
index f4ec5667..9fcec0ab 100644
--- a/src/command.cpp
+++ b/src/command.cpp
@@ -489,7 +489,7 @@ void VkCompute::record_upload(const Mat& src, VkImageMat& dst, const Option& opt
     }
 }

-void VkCompute::record_download(const VkMat& src, Mat& dst, const Option& opt)
+int VkCompute::record_download(const VkMat& src, Mat& dst, const Option& opt)
 {
     //     NCNN_LOGE("record_download buffer");

@@ -560,15 +560,54 @@ void VkCompute::record_download(const VkMat& src, Mat& dst, const Option& opt)
         dst_staging.data->stage_flags = VK_PIPELINE_STAGE_HOST_BIT;
     }

+    // Updated to use the ORT allocated buffer in dst
+    //
     // create dst
-    Mat dst_fp16;
-    dst_fp16.create_like(dst_staging, opt.blob_allocator);
-    if (dst_fp16.empty())
-        return;
+    // Mat dst_fp16;
+    // dst_fp16.create_like(dst_staging, opt.blob_allocator);
+
+    // clang-format off
+
+    // sanity check that we don't need the commented out code below
+    const bool need_TYPE_post_cast_float16_to_float32 =
+        ((dst_staging.elemsize == dst_staging.elempack * 2u) &&
+            (vkdev->info.type() == 0 && (opt.use_fp16_storage ||
+                                        (opt.use_fp16_packed && dst_staging.elempack % 4 == 0))));
+
+    if (need_TYPE_post_cast_float16_to_float32)
+    {
+        // TODO: Update the `cast to fp32 (discrete gpu)` branch below to use dst.data (assuming that is possible
+        // and valid).
+        NCNN_LOGE("The output needs to be unpacked and the current implementation doesn't support using the ORT "
+                  "Tensor buffer for that. ");
+        return -300;
+    }
+
+    if (dst_staging.dims == dst.dims &&
+        dst_staging.w == dst.w &&
+        dst_staging.h == dst.h &&
+        dst_staging.d == dst.d &&
+        dst_staging.c == dst.c &&
+        dst_staging.cstep == dst.cstep)
+    {
+        // everything matches and we can use dst directly
+    }
+    else
+    {
+        // this would be unexpected and needs investigation.
+        // if the dst.total() >= dst_staging.total() we may still be able to use dst.data.
+        NCNN_LOGE("Provided Mat for dst was not compatible with dst_staging.");
+        return -300;
+    }
+
+    // clang-format on
+
+    if (dst.empty())
+        return 0;

     // download
     d->download_post_buffers.push_back(dst_staging);
-    d->download_post_mats_fp16.push_back(dst_fp16);
+    d->download_post_mats_fp16.push_back(dst); // originally used dst_fp16

     // post memcpy device to dst
     {
@@ -580,40 +619,44 @@ void VkCompute::record_download(const VkMat& src, Mat& dst, const Option& opt)
         d->delayed_records.push_back(r);
     }

-    // cast to fp32 (discrete gpu)
-    if (dst_fp16.elemsize == dst_fp16.elempack * 2u)
-    {
-        if (vkdev->info.type() == 0 && (opt.use_fp16_storage || (opt.use_fp16_packed && dst_fp16.elempack % 4 == 0)))
-        {
-            int dims = dst_fp16.dims;
-            if (dims == 1)
-                dst.create(dst_fp16.w, (size_t)(dst_fp16.elempack * 4u), dst_fp16.elempack, opt.blob_allocator);
-            if (dims == 2)
-                dst.create(dst_fp16.w, dst_fp16.h, (size_t)(dst_fp16.elempack * 4u), dst_fp16.elempack, opt.blob_allocator);
-            if (dims == 3)
-                dst.create(dst_fp16.w, dst_fp16.h, dst_fp16.c, (size_t)(dst_fp16.elempack * 4u), dst_fp16.elempack, opt.blob_allocator);
-            if (dims == 4)
-                dst.create(dst_fp16.w, dst_fp16.h, dst_fp16.d, dst_fp16.c, (size_t)(dst_fp16.elempack * 4u), dst_fp16.elempack, opt.blob_allocator);
-
-            d->download_post_mats.push_back(dst);
+    return 0;

-            VkComputePrivate::record r;
-            r.type = VkComputePrivate::record::TYPE_post_cast_float16_to_float32;
-            r.command_buffer = 0;
-            r.post_cast_float16_to_float32.download_post_mat_fp16_offset = d->download_post_mats_fp16.size() - 1;
-            r.post_cast_float16_to_float32.download_post_mat_offset = d->download_post_mats.size() - 1;
-            r.post_cast_float16_to_float32.num_threads = opt.num_threads;
-            d->delayed_records.push_back(r);
-        }
-        else
-        {
-            dst = dst_fp16;
-        }
-    }
-    else
-    {
-        dst = dst_fp16;
-    }
+    // below is commented out due to check on need_TYPE_post_cast_float16_to_float32
+    //
+    //// cast to fp32 (discrete gpu)
+    //if (dst_fp16.elemsize == dst_fp16.elempack * 2u)
+    //{
+    //    if (vkdev->info.type() == 0 && (opt.use_fp16_storage || (opt.use_fp16_packed && dst_fp16.elempack % 4 == 0)))
+    //    {
+    //        int dims = dst_fp16.dims;
+    //        if (dims == 1)
+    //            dst.create(dst_fp16.w, (size_t)(dst_fp16.elempack * 4u), dst_fp16.elempack, opt.blob_allocator);
+    //        if (dims == 2)
+    //            dst.create(dst_fp16.w, dst_fp16.h, (size_t)(dst_fp16.elempack * 4u), dst_fp16.elempack, opt.blob_allocator);
+    //        if (dims == 3)
+    //            dst.create(dst_fp16.w, dst_fp16.h, dst_fp16.c, (size_t)(dst_fp16.elempack * 4u), dst_fp16.elempack, opt.blob_allocator);
+    //        if (dims == 4)
+    //            dst.create(dst_fp16.w, dst_fp16.h, dst_fp16.d, dst_fp16.c, (size_t)(dst_fp16.elempack * 4u), dst_fp16.elempack, opt.blob_allocator);
+
+    //        d->download_post_mats.push_back(dst);
+
+    //        VkComputePrivate::record r;
+    //        r.type = VkComputePrivate::record::TYPE_post_cast_float16_to_float32;
+    //        r.command_buffer = 0;
+    //        r.post_cast_float16_to_float32.download_post_mat_fp16_offset = d->download_post_mats_fp16.size() - 1;
+    //        r.post_cast_float16_to_float32.download_post_mat_offset = d->download_post_mats.size() - 1;
+    //        r.post_cast_float16_to_float32.num_threads = opt.num_threads;
+    //        d->delayed_records.push_back(r);
+    //    }
+    //    else
+    //    {
+    //        dst = dst_fp16;
+    //    }
+    //}
+    //else
+    //{
+    //    dst = dst_fp16;
+    //}
 }

 void VkCompute::record_download(const VkImageMat& src, Mat& dst, const Option& opt)
diff --git a/src/command.h b/src/command.h
index 88912739..cabd838d 100644
--- a/src/command.h
+++ b/src/command.h
@@ -41,7 +41,7 @@ public:

     void record_upload(const Mat& src, VkImageMat& dst, const Option& opt);

-    void record_download(const VkMat& src, Mat& dst, const Option& opt);
+    int record_download(const VkMat& src, Mat& dst, const Option& opt);

     void record_download(const VkImageMat& src, Mat& dst, const Option& opt);

diff --git a/src/layer/vulkan/shader/sigmoid.comp b/src/layer/vulkan/shader/sigmoid.comp
index bda303fd..ab06478d 100644
--- a/src/layer/vulkan/shader/sigmoid.comp
+++ b/src/layer/vulkan/shader/sigmoid.comp
@@ -32,7 +32,8 @@ layout (constant_id = shape_constant_id_offset + 4) const int cstep = 0;
 layout (binding = 0) uniform unfp sampler3D bottom_blob_3d;
 layout (binding = 1, imfmtc1) writeonly uniform unfp image3D top_blob_3d;
 #else
-layout (binding = 0) buffer bottom_top_blob { sfp bottom_top_blob_data[]; };
+layout (binding = 0) readonly buffer bottom_blob { sfp bottom_blob_data[]; };
+layout (binding = 1) writeonly buffer top_blob { sfp top_blob_data[]; };
 #endif

 layout (push_constant) uniform parameter
@@ -58,7 +59,7 @@ void main()
 #else
     const int gi = gz * psc(cstep) + gy * psc(w) + gx;

-    afp v = buffer_ld1(bottom_top_blob_data, gi);
+    afp v = buffer_ld1(bottom_blob_data, gi);
 #endif

     v = afp(1.f) / (afp(1.f) + exp(-v));
@@ -66,6 +67,6 @@ void main()
 #if NCNN_image_shader
     image3d_st1(top_blob_3d, ivec3(gx, gy, gz), v);
 #else
-    buffer_st1(bottom_top_blob_data, gi, v);
+    buffer_st1(top_blob_data, gi, v);
 #endif
 }
diff --git a/src/layer/vulkan/shader/sigmoid_pack4.comp b/src/layer/vulkan/shader/sigmoid_pack4.comp
index 129c18e5..91ba0618 100644
--- a/src/layer/vulkan/shader/sigmoid_pack4.comp
+++ b/src/layer/vulkan/shader/sigmoid_pack4.comp
@@ -32,7 +32,8 @@ layout (constant_id = shape_constant_id_offset + 4) const int cstep = 0;
 layout (binding = 0) uniform unfp sampler3D bottom_blob_3d;
 layout (binding = 1, imfmtc4) writeonly uniform unfp image3D top_blob_3d;
 #else
-layout (binding = 0) buffer bottom_top_blob { sfpvec4 bottom_top_blob_data[]; };
+layout (binding = 0) buffer bottom_blob { sfpvec4 bottom_blob_data[]; };
+layout (binding = 1) buffer top_blob { sfpvec4 top_blob_data[]; };
 #endif

 layout (push_constant) uniform parameter
@@ -58,7 +59,7 @@ void main()
 #else
     const int gi = gz * psc(cstep) + gy * psc(w) + gx;

-    afpvec4 v = buffer_ld4(bottom_top_blob_data, gi);
+    afpvec4 v = buffer_ld4(bottom_blob_data, gi);
 #endif

     v = afp(1.f) / (afp(1.f) + exp(-v));
@@ -66,6 +67,6 @@ void main()
 #if NCNN_image_shader
     image3d_st4(top_blob_3d, ivec3(gx, gy, gz), v);
 #else
-    buffer_st4(bottom_top_blob_data, gi, v);
+    buffer_st4(top_blob_data, gi, v);
 #endif
 }
diff --git a/src/layer/vulkan/shader/sigmoid_pack8.comp b/src/layer/vulkan/shader/sigmoid_pack8.comp
index 828206c5..3e4dbe16 100644
--- a/src/layer/vulkan/shader/sigmoid_pack8.comp
+++ b/src/layer/vulkan/shader/sigmoid_pack8.comp
@@ -33,7 +33,8 @@ layout (constant_id = shape_constant_id_offset + 4) const int cstep = 0;
 layout (binding = 0) uniform unfp sampler3D bottom_blob_3d;
 layout (binding = 1, imfmtc4) writeonly uniform unfp image3D top_blob_3d;
 #else
-layout (binding = 0) buffer bottom_top_blob { sfpvec8 bottom_top_blob_data[]; };
+layout (binding = 0) buffer bottom_blob { sfpvec8 bottom_blob_data[]; };
+layout (binding = 1) buffer top_blob { sfpvec8 top_blob_data[]; };
 #endif

 layout (push_constant) uniform parameter
@@ -59,7 +60,7 @@ void main()
 #else
     const int gi = gz * psc(cstep) + gy * psc(w) + gx;

-    afpvec8 v = buffer_ld8(bottom_top_blob_data, gi);
+    afpvec8 v = buffer_ld8(bottom_blob_data, gi);
 #endif

     v[0] = afp(1.f) / (afp(1.f) + exp(-v[0]));
@@ -68,6 +69,6 @@ void main()
 #if NCNN_image_shader
     image3d_st8(top_blob_3d, ivec3(gx, gy, gz), v);
 #else
-    buffer_st8(bottom_top_blob_data, gi, v);
+    buffer_st8(top_blob_data, gi, v);
 #endif
 }
diff --git a/src/layer/vulkan/sigmoid_vulkan.cpp b/src/layer/vulkan/sigmoid_vulkan.cpp
index e25b3840..8c3a5166 100644
--- a/src/layer/vulkan/sigmoid_vulkan.cpp
+++ b/src/layer/vulkan/sigmoid_vulkan.cpp
@@ -131,29 +131,35 @@ int Sigmoid_vulkan::destroy_pipeline(const Option& /*opt*/)
     return 0;
 }

-int Sigmoid_vulkan::forward_inplace(VkMat& bottom_top_blob, VkCompute& cmd, const Option& /*opt*/) const
+int Sigmoid_vulkan::forward(const VkMat& bottom_blob, VkMat& top_blob, VkCompute& cmd, const Option& /*opt*/) const
 {
-    int elempack = bottom_top_blob.elempack;
+    int elempack = bottom_blob.elempack;

-    std::vector<VkMat> bindings(1);
-    bindings[0] = bottom_top_blob;
+    std::vector<VkMat> bindings(2);
+    bindings[0] = bottom_blob;
+    bindings[1] = top_blob;

     std::vector<vk_constant_type> constants(5);
-    constants[0].i = bottom_top_blob.dims;
-    constants[1].i = bottom_top_blob.w;
-    constants[2].i = bottom_top_blob.h * bottom_top_blob.d;
-    constants[3].i = bottom_top_blob.c;
-    constants[4].i = bottom_top_blob.cstep;
+    constants[0].i = bottom_blob.dims;
+    constants[1].i = bottom_blob.w;
+    constants[2].i = bottom_blob.h * bottom_blob.d;
+    constants[3].i = bottom_blob.c;
+    constants[4].i = bottom_blob.cstep;

-    const Pipeline* pipeline = elempack == 8 ? pipeline_sigmoid_pack8
+    const Pipeline* pipeline = elempack == 8   ? pipeline_sigmoid_pack8
                                : elempack == 4 ? pipeline_sigmoid_pack4
-                               : pipeline_sigmoid;
+                                               : pipeline_sigmoid;

-    cmd.record_pipeline(pipeline, bindings, constants, bottom_top_blob);
+    cmd.record_pipeline(pipeline, bindings, constants, bottom_blob);

     return 0;
 }

+int Sigmoid_vulkan::forward_inplace(VkMat& bottom_top_blob, VkCompute& cmd, const Option& opt) const
+{
+    return forward(bottom_top_blob, bottom_top_blob, cmd, opt);
+}
+
 int Sigmoid_vulkan::forward_inplace(VkImageMat& bottom_top_blob, VkCompute& cmd, const Option& /*opt*/) const
 {
     int elempack = bottom_top_blob.elempack;
diff --git a/src/layer/vulkan/sigmoid_vulkan.h b/src/layer/vulkan/sigmoid_vulkan.h
index 1350f6a4..08155ee6 100644
--- a/src/layer/vulkan/sigmoid_vulkan.h
+++ b/src/layer/vulkan/sigmoid_vulkan.h
@@ -27,6 +27,8 @@ public:
     virtual int create_pipeline(const Option& opt);
     virtual int destroy_pipeline(const Option& opt);

+    int forward(const VkMat& bottom_blob, VkMat& top_blob, VkCompute& cmd, const Option& opt) const;
+
     using Sigmoid::forward_inplace;
     virtual int forward_inplace(VkMat& bottom_top_blob, VkCompute& cmd, const Option& opt) const;
     virtual int forward_inplace(VkImageMat& bottom_top_blob, VkCompute& cmd, const Option& opt) const;
