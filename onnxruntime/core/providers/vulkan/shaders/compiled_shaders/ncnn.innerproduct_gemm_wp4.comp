// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2021 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450
#define sfp float
#define sfpvec2 vec2
#define sfpvec4 vec4
#define sfpvec8 mat2x4
#define sfpmat4 mat4
#define afp float
#define afpvec2 vec2
#define afpvec4 vec4
#define afpvec8 mat2x4
#define afpmat4 mat4
#define lfp float
#define lfpvec4 vec4
#define sfp2lfp(v) v
#define sfp2lfpvec4(v) v
#define lfp2afp(v) v
#define lfp2afpvec4(v) v
#define buffer_ld1(buf,i) buf[i]
#define buffer_st1(buf,i,v) {buf[i]=v;}
#define buffer_cp1(buf,i,sbuf,si) {buf[i]=sbuf[si];}
#define buffer_cp1to4(buf,i,sbuf,si4) {buf[i]=vec4(sbuf[si4.r],sbuf[si4.g],sbuf[si4.b],sbuf[si4.a]);}
#define buffer_cp1to8(buf,i,sbuf,si4,sii4) {buf[i]=mat2x4(sbuf[si4.r],sbuf[si4.g],sbuf[si4.b],sbuf[si4.a],sbuf[sii4.r],sbuf[sii4.g],sbuf[sii4.b],sbuf[sii4.a]);}
#define buffer_ld2(buf,i) buf[i]
#define buffer_st2(buf,i,v) {buf[i]=v;}
#define buffer_cp2(buf,i,sbuf,si) {buf[i]=sbuf[si];}
#define buffer_ld4(buf,i) buf[i]
#define buffer_st4(buf,i,v) {buf[i]=v;}
#define buffer_cp4(buf,i,sbuf,si) {buf[i]=sbuf[si];}
#define buffer_cp4to1(buf,i4,sbuf,si) {vec4 _v=sbuf[si]; buf[i4.r]=_v.r;buf[i4.g]=_v.g;buf[i4.b]=_v.b;buf[i4.a]=_v.a;}
#define buffer_cp4to8(buf,i,sbuf,si2) {buf[i]=mat2x4(sbuf[si2.r],sbuf[si2.g]);}
#define buffer_ld8(buf,i) buf[i]
#define buffer_st8(buf,i,v) {buf[i]=v;}
#define buffer_cp8(buf,i,sbuf,si) {buf[i]=sbuf[si];}
#define buffer_cp8to1(buf,i4,ii4,sbuf,si) {mat2x4 _v=sbuf[si]; buf[i4.r]=_v[0].r;buf[i4.g]=_v[0].g;buf[i4.b]=_v[0].b;buf[i4.a]=_v[0].a; buf[ii4.r]=_v[1].r;buf[ii4.g]=_v[1].g;buf[ii4.b]=_v[1].b;buf[ii4.a]=_v[1].a;}
#define buffer_cp8to4(buf,i2,sbuf,si) {mat2x4 _v=sbuf[si]; buf[i2.r]=_v[0];buf[i2.g]=_v[1];}
#define sfp2afpmat4(v) v
#define afp2sfpmat4(v) v
#define psc(x) (x==0?p.x:x)
#define NCNN_fp16_uniform 1
#define NCNN_int8_uniform 1
#define NCNN_shader_local_memory 1

#if NCNN_fp16_storage
#extension GL_EXT_shader_16bit_storage: require
#endif
#if NCNN_fp16_arithmetic
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#endif

#extension GL_GOOGLE_include_directive: enable
// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2022 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#ifndef NCNN_VULKAN_ACTIVATION_COMP
#define NCNN_VULKAN_ACTIVATION_COMP

afp activation_afp(afp v, int activation_type, float activation_param_0, float activation_param_1)
{
    if (activation_type == 1)
    {
        v = max(v, afp(0.f));
    }
    if (activation_type == 2)
    {
        const afp slope = afp(activation_param_0);
        v = v < afp(0.f) ? v * slope : v;
    }
    if (activation_type == 3)
    {
        const afp const_min = afp(activation_param_0);
        const afp const_max = afp(activation_param_1);
        v = clamp(v, const_min, const_max);
    }
    if (activation_type == 4)
    {
        v = afp(1.f) / (afp(1.f) + exp(-v));
    }
    if (activation_type == 5)
    {
#if NCNN_moltenvk
        v = v * afp(tanh(float(log(exp(v) + afp(1.f)))));
#else
        v = v * tanh(log(exp(v) + afp(1.f)));
#endif
    }
    if (activation_type == 6)
    {
        const afp alpha = afp(activation_param_0);
        const afp beta = afp(activation_param_1);
        v = v * clamp(v * afp(alpha) + afp(beta), afp(0.f), afp(1.f));
    }

    return v;
}

afpvec4 activation_afpvec4(afpvec4 v, int activation_type, float activation_param_0, float activation_param_1)
{
    if (activation_type == 1)
    {
        v = max(v, afp(0.f));
    }
    if (activation_type == 2)
    {
        const afp slope = afp(activation_param_0);
        v = mix(v, v * afp(slope), lessThan(v, afpvec4(0.f)));
    }
    if (activation_type == 3)
    {
        const afp const_min = afp(activation_param_0);
        const afp const_max = afp(activation_param_1);
        v = clamp(v, const_min, const_max);
    }
    if (activation_type == 4)
    {
        v = afp(1.f) / (afp(1.f) + exp(-v));
    }
    if (activation_type == 5)
    {
#if NCNN_moltenvk
        v = v * afpvec4(tanh(vec4(log(exp(v) + afp(1.f)))));
#else
        v = v * tanh(log(exp(v) + afp(1.f)));
#endif
    }
    if (activation_type == 6)
    {
        const afp alpha = afp(activation_param_0);
        const afp beta = afp(activation_param_1);
        v = v * clamp(v * afp(alpha) + afp(beta), afp(0.f), afp(1.f));
    }

    return v;
}

afpvec8 activation_afpvec8(afpvec8 v, int activation_type, float activation_param_0, float activation_param_1)
{
    if (activation_type == 1)
    {
        v[0] = max(v[0], afp(0.f));
        v[1] = max(v[1], afp(0.f));
    }
    if (activation_type == 2)
    {
        const afp slope = afp(activation_param_0);
        v[0] = mix(v[0], v[0] * afp(slope), lessThan(v[0], afpvec4(0.f)));
        v[1] = mix(v[1], v[1] * afp(slope), lessThan(v[1], afpvec4(0.f)));
    }
    if (activation_type == 3)
    {
        const afp const_min = afp(activation_param_0);
        const afp const_max = afp(activation_param_1);
        v[0] = clamp(v[0], const_min, const_max);
        v[1] = clamp(v[1], const_min, const_max);
    }
    if (activation_type == 4)
    {
        v[0] = afp(1.f) / (afp(1.f) + exp(-v[0]));
        v[1] = afp(1.f) / (afp(1.f) + exp(-v[1]));
    }
    if (activation_type == 5)
    {
#if NCNN_moltenvk
        v[0] = v[0] * afpvec4(tanh(vec4(log(exp(v[0]) + afp(1.f)))));
        v[1] = v[1] * afpvec4(tanh(vec4(log(exp(v[1]) + afp(1.f)))));
#else
        v[0] = v[0] * tanh(log(exp(v[0]) + afp(1.f)));
        v[1] = v[1] * tanh(log(exp(v[1]) + afp(1.f)));
#endif
    }
    if (activation_type == 6)
    {
        const afp alpha = afp(activation_param_0);
        const afp beta = afp(activation_param_1);
        v[0] = v[0] * clamp(v[0] * afp(alpha) + afp(beta), afp(0.f), afp(1.f));
        v[1] = v[1] * clamp(v[1] * afp(alpha) + afp(beta), afp(0.f), afp(1.f));
    }

    return v;
}

#endif // NCNN_VULKAN_ACTIVATION_COMP

layout (constant_id = 0) const int bias_term = 0;
layout (constant_id = 1) const int activation_type = 0;
layout (constant_id = 2) const float activation_param_0 = 0;
layout (constant_id = 3) const float activation_param_1 = 0;

#define shape_constant_id_offset 4
layout (constant_id = shape_constant_id_offset + 0) const int dims = 0;
layout (constant_id = shape_constant_id_offset + 1) const int w = 0;
layout (constant_id = shape_constant_id_offset + 2) const int h = 0;
layout (constant_id = shape_constant_id_offset + 3) const int c = 0;
layout (constant_id = shape_constant_id_offset + 4) const int cstep = 0;

layout (constant_id = shape_constant_id_offset + 5) const int outdims = 0;
layout (constant_id = shape_constant_id_offset + 6) const int outw = 0;
layout (constant_id = shape_constant_id_offset + 7) const int outh = 0;
layout (constant_id = shape_constant_id_offset + 8) const int outc = 0;
layout (constant_id = shape_constant_id_offset + 9) const int outcstep = 0;

#if NCNN_image_shader
layout (binding = 0) uniform unfp sampler3D bottom_blob;
layout (binding = 1, imfmtc1) writeonly uniform unfp image3D top_blob;
layout (binding = 2) uniform unfp sampler3D weight_blob;
layout (binding = 3) uniform unfp sampler3D bias_blob;
#else
layout (binding = 0) readonly buffer bottom_blob { sfp bottom_blob_data[]; };
layout (binding = 1) writeonly buffer top_blob { sfp top_blob_data[]; };
#if NCNN_fp16_packed || (NCNN_fp16_storage && !NCNN_fp16_arithmetic)
// GL_EXT_shader_16bit_storage does not define f16mat4 type :(
layout (binding = 2) readonly buffer weight_blob { sfpvec4 weight_data[]; };
#else
layout (binding = 2) readonly buffer weight_blob { sfpmat4 weight_data[]; };
#endif
layout (binding = 3) readonly buffer bias_blob { sfpvec4 bias_data[]; };
#endif

layout (push_constant) uniform parameter
{
    int dims;
    int w;
    int h;
    int c;
    int cstep;

    int outdims;
    int outw;
    int outh;
    int outc;
    int outcstep;
} p;

void main()
{
    int gx = int(gl_GlobalInvocationID.x);
    int gy = int(gl_GlobalInvocationID.y);
    int gz = int(gl_GlobalInvocationID.z);

    if (gx * 4 >= psc(outw) || gy >= psc(outh) || gz >= 1)
        return;

    afpvec4 sum;

    if (bias_term == 1)
    {
#if NCNN_image_shader
        sum = image3d_ld4(bias_blob, ivec3(gx, 0, 0));
#else
        sum = buffer_ld4(bias_data, gx);
#endif
    }
    else
    {
        sum = afpvec4(0.f);
    }

#if NCNN_image_shader
    for (int i = 0; i < psc(w) / 4; i++)
    {
        afpvec4 v;
        v.r = image3d_ld1(bottom_blob, ivec3(i * 4 + 0, gy, 0));
        v.g = image3d_ld1(bottom_blob, ivec3(i * 4 + 1, gy, 0));
        v.b = image3d_ld1(bottom_blob, ivec3(i * 4 + 2, gy, 0));
        v.a = image3d_ld1(bottom_blob, ivec3(i * 4 + 3, gy, 0));

        afpmat4 k = afpmat4(
            image3d_ld4(weight_blob, ivec3(i * 4 + 0, gx, 0)),
            image3d_ld4(weight_blob, ivec3(i * 4 + 1, gx, 0)),
            image3d_ld4(weight_blob, ivec3(i * 4 + 2, gx, 0)),
            image3d_ld4(weight_blob, ivec3(i * 4 + 3, gx, 0))
        );

        sum += v * k;
    }
#else
    int v_offset = gy * psc(w);
    int w_offset = gx * psc(w) / 4;

    for (int i = 0; i < psc(w) / 4; i++)
    {
        afpvec4 v;
        v.r = buffer_ld1(bottom_blob_data, v_offset + i * 4 + 0);
        v.g = buffer_ld1(bottom_blob_data, v_offset + i * 4 + 1);
        v.b = buffer_ld1(bottom_blob_data, v_offset + i * 4 + 2);
        v.a = buffer_ld1(bottom_blob_data, v_offset + i * 4 + 3);

#if NCNN_fp16_packed || (NCNN_fp16_storage && !NCNN_fp16_arithmetic)
        // GL_EXT_shader_16bit_storage does not define f16mat4 type :(
        afpmat4 k = afpmat4(
            buffer_ld4(weight_data, (w_offset + i) * 4 + 0),
            buffer_ld4(weight_data, (w_offset + i) * 4 + 1),
            buffer_ld4(weight_data, (w_offset + i) * 4 + 2),
            buffer_ld4(weight_data, (w_offset + i) * 4 + 3)
        );
#else
        afpmat4 k = afpmat4(weight_data[w_offset + i]);
#endif

        sum += v * k;
    }
#endif

    sum = activation_afpvec4(sum, activation_type, activation_param_0, activation_param_1);

#if NCNN_image_shader
    image3d_st1(top_blob, ivec3(gx * 4 + 0, gy, 0), sum.r);
    image3d_st1(top_blob, ivec3(gx * 4 + 1, gy, 0), sum.g);
    image3d_st1(top_blob, ivec3(gx * 4 + 2, gy, 0), sum.b);
    image3d_st1(top_blob, ivec3(gx * 4 + 3, gy, 0), sum.a);
#else
    const int gi = gy * psc(outw) + gx * 4;
    buffer_st1(top_blob_data, gi + 0, sum.r);
    buffer_st1(top_blob_data, gi + 1, sum.g);
    buffer_st1(top_blob_data, gi + 2, sum.b);
    buffer_st1(top_blob_data, gi + 3, sum.a);
#endif
}
